{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xrn9Evv_1L5R"
   },
   "outputs": [],
   "source": [
    "#!pip install d2l==1.0.0-alpha1.post0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0edvnFzLfCkk"
   },
   "outputs": [],
   "source": [
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNqbygBtQRcy"
   },
   "source": [
    "# DIY CNN pour les classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihm4WGglvtV7"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRhI8OJ4bROv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiW6tl2WTKFm"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99RVXWOYmksu"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == 'cuda':\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbs8Pz5kO64W"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILt7vewVO8Z2"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSdZA76Vljvf"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zNwwScpiqUF"
   },
   "source": [
    "On va ici créer notre propre réseau de neuronnes\n",
    "\n",
    "La structure proposé est (conv2 sont de stride 1x1) : \n",
    "- **conv1** : 32 2D convolution 3x3 + ReLU activation\n",
    "- **pool1** : max pooling of 2x2\n",
    "- **conv2** : 64 convolution of 3x3 + ReLU activation\n",
    "- **pool2** : max pooling of 2x2 \n",
    "- **conv3** : 64 convolution of 3x3 + ReLU activation\n",
    "- **pool3** : max pooling of 2x2\n",
    "- **fc4** : fully connected with output of 1000 + ReLU activation\n",
    "- **fc5** : fully connected with output of 10 + SoftMax\n",
    "\n",
    "On fini sur 10 neuronnes car on va faire de la classification à 10 classes sur CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5-iZpZAlccu"
   },
   "source": [
    "### Petit conseil :  Essayer de tracer la taille de l'espaces de features et la taille de l'espaces des paramètres au travers de ce réseaux de neuronnes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9pGAPDYb7Fq"
   },
   "source": [
    "## Création du  Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3s9eC1MwoFJ8"
   },
   "source": [
    "On charge et on ouvre le dataset CIFAR10 (disponnible dans le module torchvision) et on utilise un simple pipeline de transformation qui va seulement charger les images dans un tenseur Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95rR64JYcMvb"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,\n",
    "                                        transform = transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7v3tEO1oXm8"
   },
   "source": [
    "Un ensemble de données (dataset) est une structure dotée des méthodes `__getitem__` et `__len__` implémentées. Lorsque vous appelez `__getitem__` avec l'opérateur crochet `[x]`, vous accédez au x-ième élément du dataset. Ici, dans le cas de CIFAR-10, cela signifie une image et l'entier associé à l'étiquette de classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvkj8GaEv34f"
   },
   "outputs": [],
   "source": [
    "I, l = trainset[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLOJKQNSyDrm"
   },
   "outputs": [],
   "source": [
    "I.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qYVEtmiSiW3"
   },
   "source": [
    "On remarquera ici que l'image étant un tenseur pytorch, il se situe sur la device de calcul (par exemple le GPU) pour la récupérer on va utiliser les methodes `.cpu().numpy()` pour l'affichage de plus la convention pytorch est `CxHxW` (Channel puis hauteur puis largeurs)  alors que la convention d'affichage de matplotlib est `HxWxC` on utilise donc une permutation pour intervertir la première dimension et la dèrniere :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8lP7OAtyVPZ"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(I.cpu().numpy().transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQIh6WCxyrv2"
   },
   "outputs": [],
   "source": [
    "I.cpu().numpy().transpose([1,2,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrqWRtPMyQ8e"
   },
   "outputs": [],
   "source": [
    "classes[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXPuPgw8wA5F"
   },
   "source": [
    "Affichons quelques illustrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxY2dk-BmD6R"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    _ = plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFYb0PKzmDg-"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,8))\n",
    "for x in range(4):\n",
    "    for y in range(4):\n",
    "        idx = x + 4*y\n",
    "        I, L = trainset[idx]\n",
    "        plt.subplot(4,4,idx+1)\n",
    "        imshow(I)\n",
    "        plt.title(classes[L])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJloVyWtb4P2"
   },
   "source": [
    "## Network creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LFpgrgz1gNv"
   },
   "source": [
    "Un réseau de neurones est simplement une classe qui hérite du module torch.nn et qui implémente la propagation avant (forward pass), laquelle calcule la sortie du réseau neuronal sur un mini-batch :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VABl7ZV3P7b"
   },
   "source": [
    "Par exemple je vous fournis l'implémentation du réseau suivant : \n",
    "- **conv1** 6 channels output, 5x5 | ReLU\n",
    "- **pool** 2x2 max pooling\n",
    "- **conv2** 16 channels output, 5x5 | ReLU\n",
    "- **pool** 2x2 max pooling\n",
    "- **fc1** 120 ouputs | ReLU\n",
    "- **fc2** 84 outputs | ReLU\n",
    "- **fc3** 10 outputs | ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsORgG3d1lxs"
   },
   "outputs": [],
   "source": [
    "class SampleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SampleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        self.activation = F.relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # if we decompose we have\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool(x)\n",
    "        # in one line we have \n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        \n",
    "        # here we reshape the output in [batch_size, 16x5x5] Tensor :\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        # then we apply the fully connected\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYR51u-U4Hjz"
   },
   "outputs": [],
   "source": [
    "sample = SampleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9z-HzaB5BP4"
   },
   "source": [
    "Si on veut voir la structure du réseau on peut simplement l'afficher : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBpHhUp44Uy5"
   },
   "outputs": [],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3oi80Z656qp"
   },
   "source": [
    "Une solution pour déboguer le réseau de neurones ou pour découvrir l'entrée de notre réseau est de l'éprouver avec `torch.zeros(Bs, C, H, W)` comme entrée et de chercher les bonnes valeurs de C, H, W, par exemple dans la cellule suivante j'ai trouver les dimensions d'entrée de SampleNet : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5aneIJX49UK"
   },
   "outputs": [],
   "source": [
    "H0 = 32\n",
    "C0 = 3\n",
    "W0 = 32\n",
    "sample.forward(torch.zeros(16, C0, H0, W0)).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrNuktzD18ju"
   },
   "source": [
    "## C'est a vous de jouer et d'implmémenter ClassiNet : \n",
    "\n",
    "- **conv1** : 32 2D convolution 3x3 then ReLU activation\n",
    "- **pool1** : max pooling of 2x2\n",
    "- **conv2** : 64 convolution of 3x3 then ReLU activation\n",
    "- **pool2** : max pooling of 2x2 \n",
    "- **conv3** : 64 convolution of 3x3 then ReLU activation\n",
    "- **pool3** : max pooling of 2x2\n",
    "- **fc4** : fully connected with output of 1000 then ReLU activation\n",
    "- **fc5** : fully connected with output of 10 then SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoyKCDr218Mg"
   },
   "outputs": [],
   "source": [
    "class ClassiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassiNet, self).__init__()\n",
    "        # define your layers here\n",
    "\n",
    "        self.activation = ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make your forward here \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWn9Hl5DKgM"
   },
   "source": [
    "La cellule suivante sert à valider votre implémentation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8THFegU-DPBy"
   },
   "outputs": [],
   "source": [
    "H0 = 32\n",
    "C0=3\n",
    "W0=32\n",
    "classi = ClassiNet()\n",
    "classi.forward(torch.zeros(16, C0, H0, W0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwbSDSYpO2XQ"
   },
   "source": [
    "On peut simplement calculer le nombre de paramètres de notre réseau de neuronnes en sommant le nombre de parametres par couches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmwMRHiPO1EG"
   },
   "outputs": [],
   "source": [
    "np.sum([x.numel() for x in list(classi.parameters())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMvrKUEQbysx"
   },
   "source": [
    "## Trainning fonction   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLXxVkgBlasX"
   },
   "source": [
    "Pour simplifier le codage on va définir deux fonction \n",
    "\n",
    "- train_batch qui est la phase se forward > calcul de la loss > retropropagation d'un mini-batch\n",
    "\n",
    "- train qui est la boucle total de l'apprentissage (le `fit`) et qui nous fera aussi un beau plot avec le suivit de la loss et de l'accuracy en test et train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuNwLHUTkgW0"
   },
   "outputs": [],
   "source": [
    "def train_batch(net, X, y, loss, trainer, devices):\n",
    "    \"\"\"Train for a minibatch with multiple GPUs capabilities\"\"\"\n",
    "    # on met notre batch de donnée sur la cible de calcul\n",
    "    if isinstance(X, list):\n",
    "        X = [x.to(devices[0]) for x in X]\n",
    "    else:\n",
    "        X = X.to(devices[0])\n",
    "    y = y.to(devices[0])\n",
    "    # on met notre reseau en mode 'train'\n",
    "    net.train()\n",
    "    # on initialise le gradient a zéro\n",
    "    trainer.zero_grad()\n",
    "    # on fait la prediction\n",
    "    pred = net(X)\n",
    "    # on calcul la lfonction de perte \n",
    "    l = loss(pred, y)\n",
    "    # on fait la rétro-propagation du gradient\n",
    "    l.sum().backward()\n",
    "    # on informe la descente de gradient qu'on veut faire un pas dans la descente\n",
    "    trainer.step()\n",
    "    # on sauvegarde les informations sur les prédiction en train\n",
    "    train_loss_sum = l.sum()\n",
    "    train_acc_sum = d2l.accuracy(pred, y)\n",
    "    return train_loss_sum, train_acc_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImnPFbU0mUlD"
   },
   "source": [
    "On voit ici que la grande modularité de Pytorch nous permettra de changer l'optimisateur (`trainer`) et de choisir plus tard Adam / SGD ou tout autre optimiseurs.\n",
    "\n",
    "Regardons un peut plus en détail la boucle d'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_rrIfEUmTsU"
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "               devices=d2l.try_all_gpus()):\n",
    "    \"\"\"Trainning loop\n",
    "    \n",
    "    net : le reseau de neuronnes \n",
    "    train_iter : le dataloder train\n",
    "    test_iter : le dataloader test\n",
    "    loss : la fonction de cout choisi\n",
    "    trainner : l'optimiseur choisi\n",
    "    num_epoch : le nombre d'époch \n",
    "     \"\"\"\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "\n",
    "    # plot annimation\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    \n",
    "    # declare network for multiple GPU :\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sum of training loss, sum of training accuracy, no. of examples,\n",
    "        # no. of predictions\n",
    "        metric = d2l.Accumulator(4)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            \n",
    "            # do one batch : \n",
    "            l, acc = train_batch(\n",
    "                net, features, labels, loss, trainer, devices)\n",
    "            \n",
    "            metric.add(l, acc, labels.shape[0], labels.numel())\n",
    "            timer.stop()\n",
    "            \n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (metric[0] / metric[2], metric[1] / metric[3],\n",
    "                              None))\n",
    "        \n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n",
    "          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n",
    "          f'{str(devices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MgM2ycXod7y"
   },
   "source": [
    "## L'apprentissage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRzn3oELDwNR"
   },
   "source": [
    "Pour l'apprentissage nous avons fait les choix suivant :  \n",
    "\n",
    "- une loss function de type CrossEntropy\n",
    "- l'optimiseur SGD (descente stockastique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66-sGF4oun7U"
   },
   "source": [
    "Les principaux hyper-paramètres sont : \n",
    "\n",
    "- le nombe d'epoch (nombre de fois ou on itère sur le dataset)\n",
    "- le learning_rate : le pas de descente\n",
    "- momentum :  lissage de la direction du gradient\n",
    "- batch_size : le nombre d'élément dans un mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a31fQuuNFfkb"
   },
   "outputs": [],
   "source": [
    "epoch_number = 8\n",
    "learning_rate = 0.01\n",
    "momentum = 0.6 \n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rawooAmV6bo"
   },
   "source": [
    "On construit un dataloader qui est une classe Pytorch qui encapsule le dataset et en particulier permet des chargements parallèles des données : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fv9Dj4PuDoZA"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miI7D1Kholkf"
   },
   "source": [
    "On consturit un autre dataloader mais sur l'ensemble de test cette fois-ci (qui sera un ensemble de donnée disjoint de l'ensemble de train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmwH7-g4aQeg"
   },
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X2e5Xcfovmf"
   },
   "source": [
    "Notre fonction de cout sera une Cross Entropie, un choix classique pour de la classification : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cR78dPWcF2em"
   },
   "outputs": [],
   "source": [
    "loss_crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vgv-D-bqo57p"
   },
   "source": [
    "On construit notre réseau de neuronnes et on le déplace sur le device de calcul. \n",
    "\n",
    "Et on choisi un optimiseur : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmHRkHaLFnxi"
   },
   "outputs": [],
   "source": [
    "classi = ClassiNet().to(device)\n",
    "\n",
    "optimizer = optim.SGD(classi.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D73OsILOLdX3"
   },
   "source": [
    "Trainning loop (~10 min on GPU) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWx_wIQJpJSR"
   },
   "outputs": [],
   "source": [
    "train(classi, trainloader, testloader, loss_crit, optimizer, epoch_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huwPZeQWLn2N"
   },
   "source": [
    "## Question] qu'observez-vous sur ce plot? est-il utile d'itérer plus?\n",
    "\n",
    "essayer différents hyper paramètres tel que le learning rate / batch_size voir changer l'optimizeur pour voir si vous pouvez améliorer les performances "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Adb6uWSMUxEv"
   },
   "source": [
    "## Calcul de la matrice de confusion \n",
    "\n",
    "Afin d'obtenir une vision plus précise des performances de notre réseau, il est judicieux de visualiser la matrice de confusion. Pour ce faire, nous commençons par écrire une petite fonction pour évaluer les données sur l'ensemble de test :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Zru_7JjPWqF"
   },
   "outputs": [],
   "source": [
    "def computePerf(test, net):\n",
    "    \"\"\"\n",
    "        From the test dataloader and the trained network compute the y_pred and y_true\n",
    "        vector\n",
    "    \"\"\"\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for data in test:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy()) # Save Prediction\n",
    "            y_true.extend(labels.cpu().numpy()) # Save Truth\n",
    "    return y_pred, y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NAUKCyUbFN5"
   },
   "outputs": [],
   "source": [
    "y_pred, y_true  = computePerf(testloader, classi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYzpcWMKMI8K"
   },
   "source": [
    "Calcul de la matrice de confusion  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xi0PP4TbWiN"
   },
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QWyUrVdMLk1"
   },
   "source": [
    "Affichage de la matrice de confusion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lke8E6pdcOLI"
   },
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzDLWqTecdw2"
   },
   "source": [
    "## Question ] Analysez cette matrice :\n",
    "\n",
    "- quels sont les classes les mieux classé?\n",
    "- quels sont les classes que le réseau confond le plus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASD87qdxtMHV"
   },
   "source": [
    "La précision moyenne peut simplement s'obtennir en calculant la some de la trace de la matrice de confusion :\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LofVBPOEzoXV"
   },
   "outputs": [],
   "source": [
    "def getAccuracy(conf_mat):\n",
    "    return np.trace(conf_mat/np.sum(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Owv16ByMyu5"
   },
   "source": [
    "## Plus réaliste : \n",
    "\n",
    "En général on aura tendance a repartir de models pré-éxistant, par exemple dans la cellule suivante on prend un vgg16, cependant dans le cadre de la classification il faudra toujours changer le nombre de couches final et le remplacer par une couche linéaire de bonne taille en sortie (10 classes pour CIFAR 10) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BZnk1hAUwHT"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "def getNetwork():\n",
    "    model = models.vgg16(pretrained = True)\n",
    "    input_lastLayer = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(input_lastLayer,10)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "classi = getNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJZHDZrxuHSE"
   },
   "source": [
    "# Augmentation de données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8fca184",
    "origin_pos": 0
   },
   "source": [
    "Les grand jeux de données sont un pré-requis à l'apprentissage profond. Lorsqu'on ne dispose pas d'un ensemble suffisant de donnée une solution est de faire de l'augmentation de donnée qui appliquera des transformation alléatoire (rotation, éclairage, translation, bruit, ... ) pour augmenter artificiellement la taille de notre dataset.\n",
    "\n",
    "C'est ce que nous allons mettre en oeuvre ici \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da550743",
    "origin_pos": 3
   },
   "source": [
    "## Quelques exemples d'augmentation d'images \n",
    "\n",
    "Dans cette section nous allons faire quelques tests sur un chat : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "692c8a90",
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "d2l.set_figsize()\n",
    "!wget -nv https://upload.wikimedia.org/wikipedia/commons/thumb/5/5d/Bengal_cat1.jpg/450px-Bengal_cat1.jpg -O cat1.jpg\n",
    "img = d2l.Image.open('./cat1.jpg')\n",
    "d2l.plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27fdfabf",
    "origin_pos": 6
   },
   "source": [
    "La plupart des méthodes d'augmentation de données possèdent un certain degré d'aléatoire. Afin de nous faciliter l'observation de l'effet de l'augmentation d'image, nous définissons ensuite une fonction auxiliaire `apply`. Cette fonction exécute la méthode d'augmentation d'image `aug` plusieurs fois sur l'image d'entrée `img` et montre tous les résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ef1456a3",
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):\n",
    "    Y = [aug(img) for _ in range(num_rows * num_cols)]\n",
    "    d2l.show_images(Y, num_rows, num_cols, scale=scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77ab40e9",
    "origin_pos": 8
   },
   "source": [
    "### Flipping and Cropping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db24064e",
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**Flipping the image left and right**] ne modifie généralement pas la catégorie de l'objet. Cela constitue l'une des premières méthodes et l'une des plus largement utilisées de l'augmentation d'image. Ensuite, nous utilisons le module `transforms` pour créer l'instance `RandomHorizontalFlip`, qui inverse une image de gauche à droite avec une probabilité de 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cc496a5",
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.RandomHorizontalFlip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48d88d61",
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**Flipping up and down**] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8ca5606",
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.RandomVerticalFlip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b33933f7",
    "origin_pos": 17
   },
   "source": [
    "Dans l'image d'exemple que nous avons utilisée, le chat se trouve au milieu de l'image, mais cela ne peut pas être le cas en général. \n",
    "\n",
    "Dans le code ci-dessous, nous **crop aimons aléatoirement** une zone dont l'aire est comprise entre $10\\% \\sim 100\\%$ de l'aire originale à chaque fois, et le rapport de la largeur à la hauteur de cette zone est sélectionné aléatoirement parmi les valeurs de $0.5 \\sim 2$. Ensuite, la largeur et la hauteur de la région sont toutes les deux mises à l'échelle pour atteindre 200 pixels.\n",
    "\n",
    "Sauf indication contraire, le nombre aléatoire compris entre $a$ et $b$ dans cette section fait référence à une valeur continue obtenue par échantillonnage aléatoire et uniforme de l'intervalle $[a, b]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cf463b3",
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "shape_aug = torchvision.transforms.RandomResizedCrop(\n",
    "    (200, 200), scale=(0.1, 1), ratio=(0.5, 2))\n",
    "apply(img, shape_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62a207b6",
    "origin_pos": 20
   },
   "source": [
    "### Modification de la colorimétrie\n",
    "\n",
    "On peut ajouter un peut de bruit sur la couleur en modifiant illumination / contrast et staturation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fe493e7",
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.ColorJitter(\n",
    "    brightness=0.5, contrast=0.1, saturation=0, hue=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b07b478a",
    "origin_pos": 23
   },
   "source": [
    "Plus esthétique on peut aussi changer la composante de couleure :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91bda3d2",
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.ColorJitter(\n",
    "    brightness=0, contrast=0, saturation=0, hue=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a46a09b",
    "origin_pos": 26
   },
   "source": [
    "On peut aussi tout faire a la fois : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "285ebefc",
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "color_aug = torchvision.transforms.ColorJitter(\n",
    "    brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)\n",
    "apply(img, color_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01714592",
    "origin_pos": 29
   },
   "source": [
    "### Combining Multiple Image Augmentation Methods\n",
    "En pratique, nous **associerons plusieurs méthodes d'augmentation d'image**. Par exemple, nous pouvons combiner les différentes méthodes d'augmentation d'image présentées précédemment et les appliquer à chaque image via une instance de `Compose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e39993e",
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])\n",
    "apply(img, augs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eae819c8",
    "origin_pos": 32
   },
   "source": [
    "## Apprentissage avec Augmentation\n",
    "\n",
    "Reprenons les apprentissages de CIFAR 10 mais avec une augmentation de donnée cette fois-ci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee04d79b",
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "d2l.show_images([trainset[i][0].cpu().numpy().transpose(1,2,0) for i in range(32)], 4, 8, scale=0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc24fb48",
    "origin_pos": 35
   },
   "source": [
    "Il est important de dnoter que les augmentation de données ont lieu uniquement sur les jeux de données d'apprentissage, il n'y a pas de sens à les utiliser sur l'ensemble de test (sauf pour des raison de débug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b006025a",
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "train_augs = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.ToTensor()])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a5cb91d",
    "origin_pos": 39,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "Une fonction de simplification qui construit le dataloader sur cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3833a1e0",
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def load_cifar10(is_train, augs, batch_size):\n",
    "    dataset = torchvision.datasets.CIFAR10(root=\"../data\", train=is_train,\n",
    "                                           transform=augs, download=True)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                    shuffle=is_train, num_workers=d2l.get_dataloader_workers())\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3772e3e",
    "origin_pos": 47
   },
   "source": [
    "On va apprendre un resnet18 histoire d'utiliser un réseau de neuronne de l'état de l'art.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVG2af5erjnR"
   },
   "outputs": [],
   "source": [
    "net = d2l.resnet18(10, 3)\n",
    "net.apply(d2l.init_cnn)\n",
    "\n",
    "batch_size  = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09bc8772",
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def train_with_data_aug(train_augs, test_augs, net, lr=0.001):\n",
    "    train_iter = load_cifar10(True, train_augs, batch_size)\n",
    "    test_iter = load_cifar10(False, test_augs, batch_size)\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    net(next(iter(train_iter))[0])\n",
    "    train(net, train_iter, test_iter, loss, trainer, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bc9a8d6",
    "origin_pos": 50
   },
   "source": [
    "REgardons ce que donne l'apprentissage avec augmentations : \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3c45553",
    "origin_pos": 51,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "train_with_data_aug(train_augs, test_augs, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UUF264FtNYn"
   },
   "outputs": [],
   "source": [
    "train_with_data_aug(test_augs, test_augs, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1r1TZuPoh6SX"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. tester l'impact de l'augmentation de donné sur l'apprentissage sur Cifar10\n",
    "1. jouer sur les méta-parametres ( learning rate / batch size / ...) \n",
    "1. Normalement vous devrirez pouvoir atteindre de meilleur performances en test accuracy grâce a l'augmentation de donnée en limittant l'effet d'overfiting (sur-apprentissage), essayer de voir jusqu'ou vous pouvez aller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaaCAX6WpxCb"
   },
   "source": [
    "# Finetunage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "564caccb",
    "origin_pos": 0
   },
   "source": [
    "Dans cette section nous allons mettre en pratique le fine-tunage, c'est a dire que nous allons récupérer un réseau de neuronne appris sur image-net et chercher à principallement réaprendre que la dèrnier couche.\n",
    "\n",
    "Pour cela dans pytorch cela va correspondre à fournir à l'optimizer un learning rate variable en fonction des couches (faible pour les couches a ne pas ré-apprendre et fort pour les couches à ré-apprendre)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aVlAytsd3ku"
   },
   "source": [
    "\n",
    "## Hot Dog Recognition\n",
    "\n",
    "De tout temps l'homme a chercher à reconnaitre des hot-dog, c'est pour cela que nous nous attacherons à cette tâche \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8ac143b",
    "origin_pos": 3
   },
   "source": [
    "### Reading the Dataset\n",
    "\n",
    "On a récupérer d'internet 1400 images de hot-dog et le même nombre d'images d'autre choses. On utilisera 1000 images par classes pour le train et 400 pour le test. \n",
    "\n",
    "Le code suivant télécharge et dezip les données : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a03bda9",
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "d2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip',\n",
    "                         'fba480ffa8aa7e0febbb511d181409f899b9baa5')\n",
    "\n",
    "data_dir = d2l.download_extract('hotdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6024ac9",
    "origin_pos": 5
   },
   "source": [
    "On créer nos classes datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9827ffd8",
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))\n",
    "test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e60722ae",
    "origin_pos": 8
   },
   "source": [
    "The first 8 positive examples and the last 8 negative images are shown below. As you can see, the images vary in size and aspect ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6967832c",
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "hotdogs = [train_imgs[i][0] for i in range(8)]\n",
    "not_hotdogs = [train_imgs[-i - 1][0] for i in range(8)]\n",
    "d2l.show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31c4ff9d",
    "origin_pos": 10
   },
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQq6lSZixJdf"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64ZVlPH6rS5A"
   },
   "source": [
    "## Data augmentations\n",
    "\n",
    "Au cours de l'entraînement, nous coupons d'abord une zone aléatoire de taille et de rapport d'aspect aléatoires dans l'image, puis mettons à l'échelle cette zone pour obtenir une image d'entrée de $224 \\times 224$. Lors des tests, nous mettons à l'échelle la hauteur et la largeur d'une image à 256 pixels, puis coupons une zone centrale de $224 \\times 224$ comme entrée. De plus, pour les trois canaux de couleur RVB (rouge, vert et bleu), nous *standardisons* leurs valeurs canal par canal. Concrètement, la valeur moyenne d'un canal est soustraite de chaque valeur de ce canal, puis le résultat est divisé par l'écart type de ce canal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1564a4f5",
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# Specify the means and standard deviations of the three RGB channels to\n",
    "# standardize each channel\n",
    "normalize = torchvision.transforms.Normalize(\n",
    "    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a055b8b6",
    "origin_pos": 13
   },
   "source": [
    "## Création du model \n",
    "\n",
    "On va utiliser un resnet18 pour cet exercice, il sera pré-appris sur Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "636a43b0",
    "origin_pos": 15,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "pretrained_net = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zQ77RIRk0Rg"
   },
   "source": [
    "Il est utile de connaitre le nombre de features de sortie du réseau, pour cela il suffit d'afficher la dèrniere couche (`fc` sur un resnet18) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c86987ec",
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "pretrained_net.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_QyU8Phi2qO"
   },
   "source": [
    "Question : Quel est le nombre de features de sortie du réseau et pourquoi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfe8f571",
    "origin_pos": 20
   },
   "source": [
    "Question : dans notre cas combien de features de sortie il nous faudra? et pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmAhDcCvkvw5"
   },
   "source": [
    "Création d'un réseau fine_tuné et remplacage de la couche de sortie (et son initialisation ) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f1fb2b3",
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "finetune_net = torchvision.models.resnet18(pretrained=True)\n",
    "finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2)\n",
    "nn.init.xavier_uniform_(finetune_net.fc.weight);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "739b6e6a",
    "origin_pos": 23
   },
   "source": [
    "## Fine-Tunage du Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCqzHg-OjwQe"
   },
   "source": [
    "Pour finetuner uniquement une certaine couche il suffit de ne donner que les paramètres qu'il faut optimiser a l'Optimiseur par exemple ligne 20 de la cellule suivante on va définir un learning rate 10x plus grand sur la couche de sortie que sur le reste du réseau. Ainsi l'erreur sera principallement rétropropagé sur cette partie du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38b61153",
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5,\n",
    "                      param_group=True):\n",
    "    # construct the Dataloader :\n",
    "    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'train'), transform=train_augs),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'test'), transform=test_augs),\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    devices = d2l.try_all_gpus()\n",
    "    # The Loss : \n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    # The optimizer :     \n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "             if name not in [\"fc.weight\", \"fc.bias\"]]\n",
    "        trainer = torch.optim.SGD([{'params': params_1x},\n",
    "                                   {'params': net.fc.parameters(),\n",
    "                                    'lr': learning_rate * 10}\n",
    "                                   ],\n",
    "                                lr=learning_rate, weight_decay=0.001)\n",
    "    else:\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate,\n",
    "                                  weight_decay=0.001)\n",
    "    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "                   devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f239ae9e",
    "origin_pos": 26
   },
   "source": [
    "On lance l'apprentissage : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61ace04f",
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "train_fine_tuning(finetune_net, 5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd0caf8d",
    "origin_pos": 29
   },
   "source": [
    "## Apprentissage from-scratch\n",
    "\n",
    "pour comparaison on peut faire le même exercice mais en apprenant le resnet complet non pre-trainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dc1bbe42",
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "scratch_net = torchvision.models.resnet18()\n",
    "scratch_net.fc = nn.Linear(scratch_net.fc.in_features, 2)\n",
    "train_fine_tuning(scratch_net, 5e-4, param_group=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQfDmAy90Em0"
   },
   "source": [
    "## Exercices : \n",
    "\n",
    "1. experimentez différent type de fine-tunage (jouez sur le ratio du learning rate entre les deux partie du réseau)\n",
    "1. tester sur des réseaux de neuronnes plus gros par exemple `torchvision.models.resnet101()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlbGlglS0i_b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP1t4EGcVmaWBj1HamNNRMs",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
