{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kazsp0YkuBVn"
      },
      "source": [
        "## 2. Classification linéaire : le Perceptron\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAypUVvgv4Wy"
      },
      "source": [
        "**2.1 Classification de points du plan avec un perceptron**\n",
        "\n",
        "_**Rappel du cours :**_\n",
        "Le perceptron est une architecture simple de réseau de neurones utilisée pour la classification binaire. Le modèle linéaire associé est défini par :\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(Wx + b)\n",
        "$$\n",
        "\n",
        "où $W$ est la matrice de poids, $b$ est le vecteur de biais, $x$ est l'entrée et $\\sigma$ est la fonction d'activation.\n",
        "\n",
        "La fonction d'activation la plus courante pour le perceptron est la fonction signe :\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\begin{cases}\n",
        "      1 & z \\geq 0 \\\\\n",
        "      -1 & z < 0\n",
        "   \\end{cases}\n",
        "$$\n",
        "\n",
        "Lors de l'apprentissage, on met à jour les poids et les biais avec la règle suivante :\n",
        "\n",
        "$$\n",
        "W \\leftarrow W + \\eta (y - \\hat{y})x \\\\\n",
        "b \\leftarrow b + \\eta (y - \\hat{y})\n",
        "$$\n",
        "\n",
        "où $\\eta$ est le taux d'apprentissage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stgByZmRuGZF"
      },
      "source": [
        "### 2.1   classification points du plan\n",
        "\n",
        "\n",
        "Générez un ensemble de données de points en deux dimensions avec deux classes séparables linéairement. Implémentez un perceptron qui apprend à classer ces points en utilisant la fonction signe comme fonction d'activation.\n",
        "\n",
        "**Question 1.** Générez les données : créez deux groupes de points avec des coordonnées $(x,y)$ uniformément réparties, chacun étant associé à une classe différente.\n",
        "\n",
        "``` python\n",
        "import numpy as np\n",
        "\n",
        "# Nombre de points à générer\n",
        "n_points = 100\n",
        "\n",
        "\n",
        "# Génération des données en prenant deux distribution normales\n",
        "class_1 = np.random.normal(-3, 1, size=(n_points, 2))\n",
        "class_2 = np.random.normal(3 , 1, size=(n_points, 2))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1UHMwOUvwT2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqhZEk3owJI0"
      },
      "source": [
        "\n",
        "**Question 2 :**  Affichez les points avec des marqueurs différents pour chaque classe.\n",
        "\n",
        "``` python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Affichage des points\n",
        "plt.scatter(class_1[:, 0], class_1[:, 1], marker='x', color='blue', label='Class 1')\n",
        "plt.scatter(class_2[:, 0], class_2[:, 1], marker='o', color='red', label='Class 2')\n",
        "\n",
        "plt.xlabel('X coordinate')\n",
        "plt.ylabel('Y coordinate')\n",
        "plt.legend()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFoU0_8awoIT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK8bbSuDwNJy"
      },
      "source": [
        "\n",
        "**Question 3:** Implémentez un perceptron pour classer ces points. Initialisez les poids et le biais avec des valeurs nulles.\n",
        "\n",
        "``` python\n",
        "# Fonction d'activation signe\n",
        "def sign_activation(z):\n",
        "    return 1 if z >= 0 else -1\n",
        "\n",
        "# Initialisation des poids et du biais\n",
        "weights = np.zeros(2)\n",
        "bias = 0\n",
        "learning_rate = 0.1\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki2rjJBrwQGJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbE-83cCwQuY"
      },
      "source": [
        "\n",
        "**Question 4 :** Faites une passe d'apprentissage sur l'ensemble des données. Mettez à jour les poids et le biais selon la règle d'apprentissage du perceptron.\n",
        "\n",
        "``` python\n",
        "for point, label in zip(np.vstack([class_1, class_2]), np.array([1]*n_points + [-1]*n_points)):\n",
        "    # Calcul de l'output du perceptron\n",
        "    output = sign_activation(np.dot(weights, point) + bias)\n",
        "    \n",
        "    # Mise à jour des poids et du biais\n",
        "    weights += learning_rate * (label - output) * point\n",
        "    bias += learning_rate * (label - output)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBLRi9ObwMvY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rhPOLHDwS__"
      },
      "source": [
        "\n",
        "**Question 5 :**. Tracez la ligne de séparation du perceptron sur le graphique des données.\n",
        "\n",
        "``` python\n",
        "# Coordonnées de la ligne de séparation\n",
        "x_sep = np.linspace(-2, 2, 100)\n",
        "y_sep = (-weights[0] * x_sep - bias) / weights[1]\n",
        "\n",
        "# Affichage des points et de la ligne de séparation\n",
        "plt.scatter(class_1[:, 0], class_1[:, 1], marker='x', color='blue', label='Class 1')\n",
        "plt.scatter(class_2[:, 0], class_2[:, 1], marker='o', color='red', label='Class 2')\n",
        "plt.plot(x_sep, y_sep, linestyle='--', color='green', label='Perceptron separator')\n",
        "\n",
        "plt.xlabel('X coordinate')\n",
        "plt.ylabel('Y coordinate')\n",
        "plt.legend()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QVqDTO7wUZj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEKyi-ZOuJjj"
      },
      "source": [
        "### 2.2  vitesse de convergence et séparabilité\n",
        "\n",
        "\n",
        "Dans cette question, nous allons étudier la vitesse de convergence du perceptron et observer comment il évolue en fonction du nombre d'itérations. La convergence dépend notamment de la séparabilité des données.\n",
        "\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython import display\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx-ZUmlI1y6f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PcX9G24y2Ex"
      },
      "source": [
        "**Question 1 :** Générez des données séparables et non séparables linéairement en utilisant la fonction `make_classification` de scikit-learn.\n",
        "\n",
        "pour connaitre la forme de sont appel dans une cellue de code tapez :\n",
        "```\n",
        "make_classification?\n",
        "```\n",
        "pour ouvrir l'aide de la fonction, ou alors :   \n",
        "```\n",
        "make_classification??\n",
        "```\n",
        "pour ouvrir le code de la fonction.\n",
        "\n",
        "Écrivez une fonction qui renvois un jeux de données\n",
        "```python\n",
        "def generate_data(separability = 1.0):\n",
        "    X, y = make_classification(class_sep = separability ,n_samples=100, n_features=2, n_redundant=0,  n_informative=2, n_clusters_per_class=1, random_state=42)\n",
        "    y[y == 0] = -1 # Remplacer les 0 par des -1 pour la classification binaire\n",
        "    return  X, y\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6NAA5aRy1Xo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNt-rG5OzReB"
      },
      "source": [
        "\n",
        "**Question 2 :** écrivez une fonction compute_perceptron qui calcul l'évolution de la frontière de séparation durant les itération :\n",
        "```python\n",
        "def compute_perceptron(X, y, alpha = 0.1, n_iter = 10):\n",
        "    # Implémentation de l'algorithme du perceptron\n",
        "    w = np.random.rand(3)\n",
        "    errors = []\n",
        "    w_history = [w.copy()]\n",
        "\n",
        "    for t in range(n_iter):\n",
        "        error_count = 0\n",
        "        for x, target in zip(X, y):\n",
        "            input_with_bias = np.append(x, 1)\n",
        "            prediction = np.sign(np.dot(w, input_with_bias))\n",
        "            update = alpha * (target - prediction) * input_with_bias\n",
        "            w += update\n",
        "            if target != prediction:\n",
        "                error_count += 1\n",
        "        w_history.append(w.copy())\n",
        "        errors.append(error_count)\n",
        "    return w_history, errors\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diJ58vj92bTw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r5Jf5tizYLX"
      },
      "source": [
        "\n",
        "**Question 3 :** Avec les lignes calculé on peut créer une annimation matplotlib avec la fonction suivante :\n",
        "\n",
        "```python\n",
        "def create_annimation(w_history, X, y):\n",
        "    fig, ax = plt.subplots()\n",
        "    n_iter = len(w_history)\n",
        "    def animate(i):\n",
        "        ax.clear()\n",
        "        current_w = w_history[i]\n",
        "        ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')\n",
        "        x_line = np.linspace(min(X[:, 0]), max(X[:, 0]), 100)\n",
        "        y_line = (-current_w[0] * x_line - current_w[2]) / current_w[1]\n",
        "        ax.plot(x_line, y_line, '-r')\n",
        "        ax.set_title(f\"Iteration: {i}\")\n",
        "\n",
        "    ani = FuncAnimation(fig, animate, frames=n_iter, interval=500)\n",
        "    return ani\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "X, y = generate_data(0.1)\n",
        "w_history, errors =  compute_perceptron(X, y, alpha = 0.1, n_iter = 10)\n",
        "test1 = create_annimation(w_history, X, y)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAMGWYKXzg1n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KTQwopj65Le"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvDELR07cK4a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJxSO98S5f88"
      },
      "source": [
        "```python\n",
        "test1.save(\"perceptron.gif\")\n",
        "```\n",
        "\n",
        "pour sauvegarder l'annimation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUM4upPK4AOU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqIW0TQe65Lf"
      },
      "source": [
        "pour afficher l' annimation :\n",
        "```python\n",
        "from IPython.display import Image\n",
        "Image(url='perceptron.gif')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mMQ5egj65Lf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version interactive pour explorer les paramètres :\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Variables globales pour conserver le jeu de données et éviter de le régénérer inutilement\n",
        "cached_data = None\n",
        "cached_separability = None\n",
        "\n",
        "# Définition de la fonction d'activation signe\n",
        "def sign_activation(z):\n",
        "    return 1 if z >= 0 else -1\n",
        "\n",
        "# Fonction générant deux classes en 2D avec séparabilité contrôlée\n",
        "def generate_linear_data(n_points=200, separability=6.0):\n",
        "    \"\"\"\n",
        "    Génère deux classes de points en 2D.\n",
        "    Les centres des distributions sont placés à -separability/2 et +separability/2,\n",
        "    ce qui permet de contrôler la distance entre les deux classes.\n",
        "    \"\"\"\n",
        "    center_1 = - separability / 2\n",
        "    center_2 = + separability / 2\n",
        "    class_1 = np.random.normal(loc=center_1, scale=1.0, size=(n_points, 2))\n",
        "    class_2 = np.random.normal(loc=center_2, scale=1.0, size=(n_points, 2))\n",
        "    return class_1, class_2\n",
        "\n",
        "# Fonction exécutant le perceptron sur le jeu de données (en ne régénérant le dataset que si la séparabilité change)\n",
        "def run_perceptron_interactif(n_points=500, separability=6.0, learning_rate=0.1, n_iter=10):\n",
        "    global cached_data, cached_separability\n",
        "    # Si les données n'ont jamais été générées ou si la séparabilité a changé, les générer et faire le split\n",
        "    if cached_data is None or cached_separability != separability:\n",
        "        # Génération du jeu complet (pour les deux classes)\n",
        "        class_1, class_2 = generate_linear_data(n_points=n_points, separability=separability)\n",
        "        X_full = np.vstack([class_1, class_2])\n",
        "        y_full = np.array([1]*n_points + [-1]*n_points)\n",
        "        # Mélanger les indices pour réaliser un split aléatoire\n",
        "        indices = np.random.permutation(len(X_full))\n",
        "        split_idx = int(0.8 * len(X_full))\n",
        "        train_idx = indices[:split_idx]\n",
        "        test_idx = indices[split_idx:]\n",
        "        \n",
        "        X_train = X_full[train_idx]\n",
        "        y_train = y_full[train_idx]\n",
        "        X_test = X_full[test_idx]\n",
        "        y_test = y_full[test_idx]\n",
        "        \n",
        "        cached_data = (X_train, y_train, X_test, y_test)\n",
        "        cached_separability = separability\n",
        "    else:\n",
        "        X_train, y_train, X_test, y_test = cached_data\n",
        "\n",
        "    # Initialisation des poids et du biais du perceptron (apprentissage uniquement sur le jeu d'entraînement)\n",
        "    weights = np.zeros(2)\n",
        "    bias = 0\n",
        "\n",
        "    # Phase d'apprentissage sur le jeu train, sur n_iter passages complets\n",
        "    for _ in range(n_iter):\n",
        "        for point, label in zip(X_train, y_train):\n",
        "            prediction = sign_activation(np.dot(weights, point) + bias)\n",
        "            update = learning_rate * (label - prediction)\n",
        "            weights += update * point\n",
        "            bias += update\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, weights, bias\n",
        "\n",
        "# Fonction d'affichage de la frontière de décision et des points avec mise en forme spécifique\n",
        "def afficher_frontiere(learning_rate, n_iter, separability):\n",
        "    # Exécution de l'entraînement avec les paramètres choisis\n",
        "    X_train, y_train, X_test, y_test, weights, bias = run_perceptron_interactif(\n",
        "        learning_rate=learning_rate, n_iter=n_iter, separability=separability\n",
        "    )\n",
        "    \n",
        "    # Prédiction sur les jeux d'entraînement et de test\n",
        "    pred_train = np.array([sign_activation(np.dot(weights, x) + bias) for x in X_train])\n",
        "    pred_test  = np.array([sign_activation(np.dot(weights, x) + bias) for x in X_test])\n",
        "    \n",
        "    # Calcul des accuracies\n",
        "    train_acc = np.mean(pred_train == y_train)\n",
        "    test_acc  = np.mean(pred_test == y_test)\n",
        "    \n",
        "    # Identification des indices mal classifiés par jeu et par classe\n",
        "    idx_train_c1 = np.where((y_train == 1))[0]\n",
        "    idx_train_c2 = np.where((y_train == -1))[0]\n",
        "    idx_test_c1  = np.where((y_test == 1))[0]\n",
        "    idx_test_c2  = np.where((y_test == -1))[0]\n",
        "    \n",
        "    idx_err_train_c1 = np.where((pred_train != y_train) & (y_train == 1))[0]\n",
        "    idx_err_train_c2 = np.where((pred_train != y_train) & (y_train == -1))[0]\n",
        "    idx_err_test_c1  = np.where((pred_test != y_test) & (y_test == 1))[0]\n",
        "    idx_err_test_c2  = np.where((pred_test != y_test) & (y_test == -1))[0]\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    \n",
        "    # Affichage des données train avec des ronds pleins\n",
        "    plt.scatter(X_train[idx_train_c1, 0], X_train[idx_train_c1, 1],\n",
        "                c='blue', marker='o', label='Train Classe 1')\n",
        "    plt.scatter(X_train[idx_train_c2, 0], X_train[idx_train_c2, 1],\n",
        "                c='red', marker='o', label='Train Classe 2')\n",
        "    \n",
        "    # Affichage des données test avec des croix\n",
        "    plt.scatter(X_test[idx_test_c1, 0], X_test[idx_test_c1, 1],\n",
        "                c='blue', marker='x', label='Test Classe 1')\n",
        "    plt.scatter(X_test[idx_test_c2, 0], X_test[idx_test_c2, 1],\n",
        "                c='red', marker='x', label='Test Classe 2')\n",
        "    \n",
        "    # Surimpression des erreurs train : entourées d'un carré\n",
        "    if idx_err_train_c1.size > 0:\n",
        "        plt.scatter(X_train[idx_err_train_c1, 0], X_train[idx_err_train_c1, 1],\n",
        "                    facecolors='none', edgecolors='blue', marker='s', s=150,\n",
        "                    label='Erreur Train Classe 1')\n",
        "    if idx_err_train_c2.size > 0:\n",
        "        plt.scatter(X_train[idx_err_train_c2, 0], X_train[idx_err_train_c2, 1],\n",
        "                    facecolors='none', edgecolors='red', marker='s', s=150,\n",
        "                    label='Erreur Train Classe 2')\n",
        "    \n",
        "    # Surimpression des erreurs test : entourées d'un cercle\n",
        "    if idx_err_test_c1.size > 0:\n",
        "        plt.scatter(X_test[idx_err_test_c1, 0], X_test[idx_err_test_c1, 1],\n",
        "                    facecolors='none', edgecolors='blue', marker='o', s=150,\n",
        "                    label='Erreur Test Classe 1')\n",
        "    if idx_err_test_c2.size > 0:\n",
        "        plt.scatter(X_test[idx_err_test_c2, 0], X_test[idx_err_test_c2, 1],\n",
        "                    facecolors='none', edgecolors='red', marker='o', s=150,\n",
        "                    label='Erreur Test Classe 2')\n",
        "    \n",
        "    # Calcul et affichage de la frontière de décision\n",
        "    x_min, x_max = plt.xlim()\n",
        "    x_vals = np.linspace(x_min - 1, x_max + 1, 100)\n",
        "    if weights[1] != 0:\n",
        "        y_vals = (-weights[0] * x_vals - bias) / weights[1]\n",
        "        plt.plot(x_vals, y_vals, 'g--', label='Frontière de décision')\n",
        "    else:\n",
        "        plt.axvline(x=-bias / weights[0], color='g', linestyle='--', label='Frontière de décision')\n",
        "    \n",
        "    plt.xlabel('Coordonnée X')\n",
        "    plt.ylabel('Coordonnée Y')\n",
        "    plt.title(f\"Perceptron\\nLR = {learning_rate}, Iterations = {n_iter}, Séparabilité = {separability}\\n\"\n",
        "              f\"Train Accuracy = {train_acc*100:.1f}%, Test Accuracy = {test_acc*100:.1f}%\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Création des sliders interactifs\n",
        "lr_slider = widgets.FloatSlider(value=0.1, min=0.01, max=100.0, step=0.01, description='Learning Rate:')\n",
        "iter_slider = widgets.IntSlider(value=10, min=1, max=50, step=1, description='Iterations:')\n",
        "sep_slider = widgets.FloatSlider(value=3.0, min=0.1, max=5.0, step=0.1, description='Séparabilité:')\n",
        "\n",
        "# Liaison de l'interactivité aux trois sliders\n",
        "widgets.interact(afficher_frontiere, learning_rate=lr_slider, n_iter=iter_slider, separability=sep_slider)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QTkeM5Wp97Vx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25alerPOuQZH"
      },
      "source": [
        "### Ouverture\n",
        "\n",
        "On peut essayer de faire varier les parametres de l'apprentissage : le alpha et le nombre d'iterations\n",
        "\n",
        "On peut aussi regarder comment converge l'estimation en fonction de alpha et de la séparabilité des données\n",
        "\n",
        "En dehors de l'intéret pédagogique une fois qu'on a compris comment fonctionne un perceptron on a tout intéret à utiliser des version déja implémenter.\n",
        "\n",
        "Le code suivant reproduit l'expérience plus haute dans un cadre ou on peut changer la dimension de l'espace d'entré (plus seulement 2D) et fait une optimisation des hyperparamètre du perceptron (nombre d'itérations et pas de descente) :\n",
        "\n",
        "```python\n",
        "# grid search total epochs for the perceptron\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# defintion d'un jeux de données, ici on peut jouer sur la taille (n_features) et la spéparabilité des classes\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, class_sep=0.9 ,  n_redundant=0, random_state=1)\n",
        "\n",
        "# definition d'un model de perceptron\n",
        "model = Perceptron(eta0=0.0001)\n",
        "\n",
        "\n",
        "# definition du mode d'évaluation par cross validation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# definition de la grille d'exploration des paramètres\n",
        "grid = dict()\n",
        "# On chois\n",
        "grid['max_iter'] = [1, 10, 100, 1000, 10000, 100000]\n",
        "grid['eta0'] = [0.1, 0.01, 0.001, 0.0001]\n",
        "\n",
        "# la recherche du parametrage optimal :\n",
        "search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "results = search.fit(X, y)\n",
        "\n",
        "# le résultat\n",
        "print('Mean Accuracy: %.3f' % results.best_score_)\n",
        "print('Config: %s' % results.best_params_)\n",
        "# summarize all\n",
        "means = results.cv_results_['mean_test_score']\n",
        "params = results.cv_results_['params']\n",
        "for mean, param in zip(means, params):\n",
        "    print(\">%.3f with: %r\" % (mean, param))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgNQuEjEvxbc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGaL6uKlSQhZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}